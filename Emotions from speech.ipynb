{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from speechemotionrecognition.mlmodel import NN, SVM, RF\n",
    "from speechemotionrecognition.utilities import get_data, class_labels\n",
    "import sys\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM as lstm, Dense, Dropout, Conv2D, Flatten, \\\n",
    "    BatchNormalization, Activation, MaxPooling2D\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import speechpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Neutral\", \"Angry\", \"Happy\", \"Sad\"]\n",
    "mslen = 32000  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(filename):\n",
    "    \"\"\"\n",
    "    Read the wav file and return corresponding data\n",
    "    :param filename: name of the file\n",
    "    :return: return tuple containing sampling frequency and signal\n",
    "    \"\"\"\n",
    "    return wav.read(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset_path, flatten=True, mfcc_len=39):\n",
    "    \"\"\"\n",
    "    Read the files get the data perform the test-train split and return them to the caller\n",
    "    :param dataset_path: path to the dataset folder\n",
    "    :param mfcc_len: Number of mfcc features to take for each frame\n",
    "    :param flatten: Boolean specifying whether to flatten the data or not\n",
    "    :return: 4 arrays, x_train x_test y_train y_test\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_fs = 0\n",
    "    s = 0\n",
    "    cnt = 0\n",
    "    cur_dir = os.getcwd()\n",
    "    #print('curdir', cur_dir)\n",
    "    os.chdir(dataset_path)\n",
    "    for i, directory in enumerate(class_labels):\n",
    "        #print( \"started reading folder\", directory)\n",
    "        os.chdir(directory)\n",
    "        for filename in os.listdir('.'):\n",
    "            fs, signal = read_wav(filename)\n",
    "            #print((signal))\n",
    "            #print(fs)\n",
    "            max_fs = max(max_fs, fs)\n",
    "            s_len = len(signal)\n",
    "            #print(s_len)\n",
    "            # pad the signals to have same size if lesser than required\n",
    "            # else slice them\n",
    "            if s_len < mslen:\n",
    "                pad_len = mslen - s_len\n",
    "                pad_rem = pad_len % 2\n",
    "                pad_len /= 2\n",
    "                p=int(pad_len)\n",
    "                               \n",
    "                \n",
    "                signal = np.pad(signal, (p + pad_rem), 'constant', constant_values=0)\n",
    "            else:\n",
    "                pad_len = s_len - mslen\n",
    "                pad_len /= 2\n",
    "                p=int(pad_len)\n",
    "                signal = signal[p:p + mslen]\n",
    "                \n",
    "            mfcc = speechpy.feature.mfcc(signal, fs, num_cepstral=mfcc_len)\n",
    "            \n",
    "\n",
    "            if flatten:\n",
    "                # Flatten the data\n",
    "                mfcc = mfcc.flatten()\n",
    "            data.append(mfcc)\n",
    "            labels.append(i)\n",
    "            cnt += 1\n",
    "        #print (\"ended reading folder\", directory)\n",
    "        os.chdir('..')\n",
    "    os.chdir(cur_dir)\n",
    "    \n",
    "    #x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    return  np.array(labels), np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaibhav.singh/anaconda3/lib/python3.7/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 198, 39)\n",
      "(339, 7722)\n"
     ]
    }
   ],
   "source": [
    "labels, ds = get_data(dataset_path=dataset_path, flatten=False)\n",
    "print(ds.shape)\n",
    "\n",
    "\n",
    "nsamples, nx, ny = ds.shape\n",
    "d2 = ds.reshape((nsamples,nx*ny))\n",
    "print(d2.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(d2, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm \n",
      "\n",
      "accuracy\n",
      "0.8088235294117647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm=SVC(kernel=\"linear\",C=0.05,random_state=101)\n",
    "svm.fit(x_train,y_train)\n",
    "y_pred6=svm.predict(x_test)\n",
    "print(\"svm \\n\")\n",
    "print(\"accuracy\")\n",
    "print(svm.score(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56 89 63 41]\n"
     ]
    }
   ],
   "source": [
    "k=(svm.n_support_)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive baiyes\n",
      "\n",
      "accuracy\n",
      "0.6617647058823529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.10)\n",
    "bnb.fit(x_train, y_train)\n",
    "y_pred4 = bnb.predict(x_test)\n",
    "\n",
    "print(\"naive baiyes\\n\")\n",
    "print(\"accuracy\")\n",
    "print(bnb.score(x_test,y_test))\n",
    "#print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 198, 39)\n",
      "WARNING:tensorflow:From /Users/vaibhav.singh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 182, 36, 64)       4416      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 182, 36, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 88,580\n",
      "Trainable params: 88,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(ds, labels, test_size=0.2, random_state=42)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model= Sequential()\n",
    "model.add(Conv2D(64, (17,4),input_shape=(x_train.shape[1],x_train.shape[2],1)))\n",
    "model.add((Activation('relu')))\n",
    "model.add(MaxPooling2D(pool_size=(10, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),))\n",
    "model.add((Activation('relu')))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 198, 39)\n",
      "(68, 198, 39)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 198, 39, 1)\n",
      "(68, 198, 39, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vaibhav.singh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 253 samples, validate on 18 samples\n",
      "Epoch 1/10\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5549 - acc: 0.7362 - val_loss: 0.4675 - val_acc: 0.7917\n",
      "Epoch 2/10\n",
      "253/253 [==============================] - 1s 6ms/step - loss: 0.4283 - acc: 0.7994 - val_loss: 0.4016 - val_acc: 0.8056\n",
      "Epoch 3/10\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.3229 - acc: 0.8449 - val_loss: 0.2860 - val_acc: 0.9167\n",
      "Epoch 4/10\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.2327 - acc: 0.9190 - val_loss: 0.2954 - val_acc: 0.8472\n",
      "Epoch 5/10\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.1782 - acc: 0.9397 - val_loss: 0.2113 - val_acc: 0.9167\n",
      "Epoch 6/10\n",
      "253/253 [==============================] - 1s 6ms/step - loss: 0.1507 - acc: 0.9377 - val_loss: 0.2649 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.1176 - acc: 0.9575 - val_loss: 0.2174 - val_acc: 0.9167\n",
      "Epoch 8/10\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.0936 - acc: 0.9704 - val_loss: 0.2007 - val_acc: 0.8611\n",
      "Epoch 9/10\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.0554 - acc: 0.9951 - val_loss: 0.1765 - val_acc: 0.9167\n",
      "Epoch 10/10\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.0329 - acc: 0.9960 - val_loss: 0.2905 - val_acc: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3303beb8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=10,validation_split=0.065)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 8ms/step\n",
      "0.323242338265\n",
      "0.860294117647\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(loss)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.1073 - acc: 0.9640\n",
      "68/68 [==============================] - 0s 7ms/step\n",
      "0\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 17ms/step - loss: 0.0838 - acc: 0.9760\n",
      "68/68 [==============================] - 0s 7ms/step\n",
      "1\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 17ms/step - loss: 0.0719 - acc: 0.9806\n",
      "68/68 [==============================] - 0s 7ms/step\n",
      "2\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 18ms/step - loss: 0.0482 - acc: 0.9908\n",
      "68/68 [==============================] - 0s 7ms/step\n",
      "3\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0373 - acc: 0.9899\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "4\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0224 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "5\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 23ms/step - loss: 0.0170 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "6\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 22ms/step - loss: 0.0146 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "7\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0101 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "8\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0067 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "9\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0055 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "10\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0048 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "11\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0040 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "12\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0033 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "13\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0029 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "14\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0026 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "15\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0023 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "16\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 22ms/step - loss: 0.0021 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "17\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 22ms/step - loss: 0.0019 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "18\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0018 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 9ms/step\n",
      "19\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0017 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 10ms/step\n",
      "20\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0016 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "21\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0015 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "22\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0013 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "23\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0012 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "24\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0011 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 7ms/step\n",
      "25\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0011 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "26\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0010 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "27\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 24ms/step - loss: 9.4962e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "28\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 9.0638e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "29\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 8.4278e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 7ms/step\n",
      "30\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 8.0009e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "31\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 7.4502e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "32\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 7.2107e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "33\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 6.7653e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "34\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 6.4854e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "35\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 6.1788e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "36\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 5.8807e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "37\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 5.7456e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 9ms/step\n",
      "38\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 22ms/step - loss: 5.3958e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "39\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 5.1886e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "40\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 4.9248e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 9ms/step\n",
      "41\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 4.7404e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "42\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 4.5707e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "43\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 4.3359e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "44\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 4.1910e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "45\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 4.0802e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "46\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 3.8962e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "47\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 3.7385e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "48\n",
      "Epoch 1/1\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 3.6031e-04 - acc: 1.0000\n",
      "68/68 [==============================] - 1s 8ms/step\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for i in range(50):\n",
    "    # Shuffle the data for each epoch in unison inspired from https://stackoverflow.com/a/4602224\n",
    "    p = np.random.permutation(len(x_train))\n",
    "    x_train = x_train[p]\n",
    "    y_train = y_train[p]\n",
    "    model.fit(x_train, y_train, batch_size=32, epochs=1)\n",
    "    loss, acc = model.evaluate(x_test, y_test)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "    print(i)    \n",
    "trained = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933823529412\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa    \n",
    "filename=\"C:/Users/vaibhav singh/Desktop/emotion/speech-emotion-recognition-master/angry.wav\"\n",
    "filename2=\"C:/Users/vaibhav singh/Desktop/emotion/speech-emotion-recognition-master/happy.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_fx(file):\n",
    "    data=[]\n",
    "    max_fs=0\n",
    "    signal, fs = librosa.load(file, sr=16000)\n",
    "    max_fs = max(max_fs, fs)\n",
    "    s_len = len(signal)\n",
    "    if s_len < mslen:\n",
    "        pad_len = mslen - s_len\n",
    "        pad_rem = pad_len % 2\n",
    "        pad_len /= 2\n",
    "        p=int(pad_len)\n",
    "        signal = np.pad(signal, (p + pad_rem), 'constant', constant_values=0)\n",
    "    else:\n",
    "        pad_len = s_len - mslen\n",
    "        pad_len /= 2\n",
    "        p=int(pad_len)\n",
    "        signal = signal[p:p + mslen]\n",
    "    mfcc = speechpy.feature.mfcc(signal, fs, num_cepstral=39)\n",
    "    print(mfcc.shape)\n",
    "    data.append(mfcc)\n",
    "    x_trainn=np.array(data)\n",
    "    x_trainn = x_trainn.reshape(x_trainn.shape[0],x_trainn.shape[1],x_trainn.shape[2],1)\n",
    "    pr=model.predict(x_trainn).tolist()\n",
    "    print(pr)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 39)\n",
      "[[1.9956779340191133e-08, 0.9933685660362244, 0.006631484720855951, 2.1043168985102056e-08]]\n",
      "(198, 39)\n",
      "[[0.9999994039535522, 3.0564244468678226e-08, 1.3592926961791818e-07, 5.186241196497576e-07]]\n"
     ]
    }
   ],
   "source": [
    "get_data_fx(filename)\n",
    "get_data_fx(filename2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 128)               86016     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 90,740\n",
      "Trainable params: 90,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(ds, labels, test_size=0.2, random_state=42)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(lstm(128, input_shape=(198,39)))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(16, activation='tanh'))\n",
    "model2.add(Dense(4, activation='softmax'))       \n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model2.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(x_train,y_train,batch_size=32,epochs=10,validation_split=0.065)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
